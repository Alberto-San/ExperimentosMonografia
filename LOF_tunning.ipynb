{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt8lok0Ucpc+OTD9XrL3hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alberto-San/ExperimentosMonografia/blob/main/LOF_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "def load_data():\n",
        "  path = \"color_statistics.csv\"\n",
        "  class_label = \"class\"\n",
        "  label = \"im_Superficial-Intermediate\"\n",
        "  path_label = \"image_path\"\n",
        "  table = pd.read_csv(path)\n",
        "  labels = list(table[class_label].drop_duplicates().values)\n",
        "  data = {}\n",
        "\n",
        "  for label in labels:\n",
        "    table_label = table[table[class_label] == label]\n",
        "    columns_to_drop = [class_label, path_label]\n",
        "    X = table_label.drop(columns_to_drop, axis=1)\n",
        "    data[label] = {}\n",
        "    data[label][\"table\"] = X\n",
        "\n",
        "  return data, labels"
      ],
      "metadata": {
        "id": "vjpYG0CEApQr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lEveln5Ak2G",
        "outputId": "8cce4d48-98e8-4ec4-dd87-7cf52cbc9ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label is im_Superficial-Intermediate\n",
            "Best n_neighbors: 5\n",
            "Best contamination: 0.05\n",
            "Best mean squared error: 0.11552346570397112\n",
            "Label is im_Dyskeratotic\n",
            "Best n_neighbors: 5\n",
            "Best contamination: 0.05\n",
            "Best mean squared error: 0.11316113161131611\n",
            "Label is im_Parabasal\n",
            "Best n_neighbors: 5\n",
            "Best contamination: 0.05\n",
            "Best mean squared error: 0.09148665819567979\n",
            "Label is im_Metaplastic\n",
            "Best n_neighbors: 5\n",
            "Best contamination: 0.05\n",
            "Best mean squared error: 0.10592686002522068\n",
            "Label is im_Koilocytotic\n",
            "Best n_neighbors: 5\n",
            "Best contamination: 0.05\n",
            "Best mean squared error: 0.11636363636363636\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def find_best_hyperparameters(data, label):\n",
        "  X = data[label][\"table\"]\n",
        "\n",
        "  # Load your data\n",
        "  X = X.to_numpy()\n",
        "\n",
        "  # Define the range of values for n_neighbors and contamination to try\n",
        "  n_neighbors_values = [5, 10, 15, 20]\n",
        "  contamination_values = [value/100 for value in range(5, 50, 5)]\n",
        "\n",
        "  # Initialize variables to store the best parameters and the corresponding mean squared error\n",
        "  best_n_neighbors = None\n",
        "  best_contamination = None\n",
        "  best_mse = np.inf\n",
        "\n",
        "  # Perform the grid search on the data\n",
        "  for n_neighbors in n_neighbors_values:\n",
        "      for contamination in contamination_values:\n",
        "          # Define the LOF model with the current parameter values\n",
        "          lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, novelty=True)\n",
        "\n",
        "          # Fit the model on the data\n",
        "          lof.fit(X)\n",
        "\n",
        "          # Compute the mean squared error of the predictions\n",
        "          y_pred = lof.predict(X)\n",
        "          mse = mean_squared_error(np.ones(len(X)), y_pred)\n",
        "\n",
        "          # Update the best parameters and the corresponding mean squared error\n",
        "          if mse < best_mse:\n",
        "              best_n_neighbors = n_neighbors\n",
        "              best_contamination = contamination\n",
        "              best_mse = mse\n",
        "\n",
        "  # Print the best parameters and the corresponding mean squared error\n",
        "  print(\"Label is {}\".format(label))\n",
        "  print(\"Best n_neighbors:\", best_n_neighbors)\n",
        "  print(\"Best contamination:\", best_contamination)\n",
        "  print(\"Best mean squared error:\", best_mse)\n",
        "\n",
        "  data[label][\"best_params\"] = {\n",
        "      \"best_n_neighbors\": best_n_neighbors,\n",
        "      \"best_contamination\": best_contamination,\n",
        "      \"best_mse\": best_mse\n",
        "  }\n",
        "  return data\n",
        "\n",
        "data, labels = load_data()\n",
        "\n",
        "for label in labels:\n",
        "  data = find_best_hyperparameters(data, label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0DwosqBgVN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}